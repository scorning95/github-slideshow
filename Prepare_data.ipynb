{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prepare_data",
      "provenance": [],
      "collapsed_sections": [
        "_XsPOeaRPUlk",
        "fZEbbWaoPYRk",
        "a2yNPswcPamo",
        "1rnCabCrVaBQ",
        "pmvLWo-vVe7X",
        "OSlo8-jSVprv",
        "UQD2WqjLRaBN",
        "QJmKKJu_RwPD",
        "eS2mtx62WG6k"
      ],
      "authorship_tag": "ABX9TyMfxwGO1x/9JcV2jf9OdORV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scorning95/github-slideshow/blob/main/Prepare_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Goal:\n",
        "Select 100 random pixels from each land class type.\n",
        "\n",
        "Extract values for these 600 pixels from available images.\n",
        "\n",
        "Select 10 triplets for each pixel for training, and 5 triplets for testing (6000 rows and 3000 rows, respectively)."
      ],
      "metadata": {
        "id": "FTOEs9UPQHOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to drive"
      ],
      "metadata": {
        "id": "_XsPOeaRPUlk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZikEkStqOwM8",
        "outputId": "4af984f6-b974-49b7-8f8a-b31e57508ac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "directory = '/content/drive/MyDrive/ColabNotebooks/autoencoders/'\n",
        "#directory = 'C:/Users/student/shelby'\n",
        "os.chdir(directory)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rioxarray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "105j-vE8PblR",
        "outputId": "1293ce80-77bd-4806-9ca9-0d998a72e867"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rioxarray\n",
            "  Downloading rioxarray-0.9.1.tar.gz (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 2.8 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.2.10-cp37-cp37m-manylinux1_x86_64.whl (19.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.3 MB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from rioxarray) (21.3)\n",
            "Requirement already satisfied: xarray>=0.17 in /usr/local/lib/python3.7/dist-packages (from rioxarray) (0.20.2)\n",
            "Collecting pyproj>=2.2\n",
            "  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 53.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from pyproj>=2.2->rioxarray) (2022.6.15)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.7/dist-packages (from xarray>=0.17->rioxarray) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7 in /usr/local/lib/python3.7/dist-packages (from xarray>=0.17->rioxarray) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from xarray>=0.17->rioxarray) (4.12.0)\n",
            "Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.7/dist-packages (from xarray>=0.17->rioxarray) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1->xarray>=0.17->rioxarray) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1->xarray>=0.17->rioxarray) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1->xarray>=0.17->rioxarray) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->xarray>=0.17->rioxarray) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->rioxarray) (3.0.9)\n",
            "Collecting affine\n",
            "  Downloading affine-2.3.1-py2.py3-none-any.whl (16 kB)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio->rioxarray) (57.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio->rioxarray) (22.1.0)\n",
            "Collecting click-plugins\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio->rioxarray) (7.1.2)\n",
            "Building wheels for collected packages: rioxarray\n",
            "  Building wheel for rioxarray (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rioxarray: filename=rioxarray-0.9.1-py3-none-any.whl size=54611 sha256=25a11a202d1c445e0570cca36f2725fecf688ad09a19c71f216bc68cad8d752d\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/da/9e/1cc57b2e7a29a206893db83e984a341e2e94378263e0798229\n",
            "Successfully built rioxarray\n",
            "Installing collected packages: snuggs, cligj, click-plugins, affine, rasterio, pyproj, rioxarray\n",
            "Successfully installed affine-2.3.1 click-plugins-1.1.1 cligj-0.7.2 pyproj-3.2.1 rasterio-1.2.10 rioxarray-0.9.1 snuggs-1.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to libraries"
      ],
      "metadata": {
        "id": "fZEbbWaoPYRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "### Packages and fun\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import rioxarray as rxr\n",
        "import xarray as xr\n",
        "import rasterio\n",
        "import os\n",
        "import pandas as pd\n",
        "from random import random\n",
        "from random import seed\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import random\n",
        "from rasterio.plot import show\n",
        "import rasterio.plot"
      ],
      "metadata": {
        "id": "ZEatuq6GPaEC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define pathways"
      ],
      "metadata": {
        "id": "a2yNPswcPamo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "### Define directories\n",
        "data_dir = f'{directory}data/'\n",
        "cf_dir = f'{data_dir}S2_BPWW_UTM/cloudfree/'\n",
        "\n",
        "### Create/define folder\n",
        "tables_dir = f'{data_dir}tables/'\n",
        "if not os.path.exists(tables_dir):\n",
        "    os.mkdir(tables_dir)"
      ],
      "metadata": {
        "id": "IvUHmUlePi0b"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Date functions"
      ],
      "metadata": {
        "id": "1rnCabCrVaBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "# functions to get date and doy from files\n",
        "def filedate(x):\n",
        "    return(x[-14:-4])\n",
        "\n",
        "def is_leap_year(year):\n",
        "    if year % 100 == 0:\n",
        "        return year % 400 == 0\n",
        "    return year % 4 == 0\n",
        "\n",
        "# Date to DOY; requires is_leap_year result and Y, M, D\n",
        "def get_doy(Y,M,D):\n",
        "    \"\"\" given year, month, day return day of year\n",
        "        Astronomical Algorithms, Jean Meeus, 2d ed, 1998, chap 7 \"\"\"\n",
        "    if is_leap_year(Y):\n",
        "        K = 1\n",
        "    else:\n",
        "        K = 2\n",
        "    my_doy = int((275 * M) / 9.0) - K * int((M + 9) / 12.0) + D - 30\n",
        "    return my_doy\n",
        "\n",
        "def cumulative_doy(image):\n",
        "    begin_y = 2017\n",
        "    leap_year = [1956,1960,1964,1968,1972,1976,1980,1984,1988,1992,1996,2000,\n",
        "                 2004,2008,2012,2016,2020,2024,2028,2032,2036,2040,2044,2048]\n",
        "    date = filedate(image)\n",
        "    Y,M,D = splitter(date)\n",
        "    doy = get_doy(Y,M,D)\n",
        "    if Y == begin_y:\n",
        "        return doy, Y\n",
        "    else:\n",
        "        year = begin_y\n",
        "        count = 0\n",
        "        while Y > year:\n",
        "            if year in leap_year:\n",
        "                count += 366\n",
        "            else:\n",
        "                count += 365\n",
        "            year += 1\n",
        "        cum_doy = doy + count\n",
        "        return cum_doy, Y\n",
        "\n",
        "def cyclical_doy(doy, Y):\n",
        "    if is_leap_year(Y):\n",
        "        doy_sin = np.sin(2 * np.pi * doy/366.)\n",
        "        doy_cos = np.cos(2 * np.pi * doy/366.)\n",
        "        return doy_sin, doy_cos\n",
        "    else:\n",
        "        doy_sin = np.sin(2 * np.pi * doy/365.)\n",
        "        doy_cos = np.cos(2 * np.pi * doy/365.)\n",
        "        return doy_sin, doy_cos\n",
        "\n",
        "def splitter(date):\n",
        "    y = int(date.split('-')[0])\n",
        "    m = int(date.split('-')[1])\n",
        "    d = int(date.split('-')[2])\n",
        "    return y, m, d\n",
        "\n",
        "def one_step(image):\n",
        "  date = filedate(image)\n",
        "  y,m,d = splitter(date)\n",
        "  dofy = get_doy(y,m,d)\n",
        "  doy_sin, doy_cos = cyclical_doy(dofy,y)\n",
        "  return y, dofy, doy_sin, doy_cos"
      ],
      "metadata": {
        "id": "rgcDEYyRVd5U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random pixels"
      ],
      "metadata": {
        "id": "pmvLWo-vVe7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 = farmland\n",
        "\n",
        "2 = grassland\n",
        "\n",
        "3 = broadleaf\n",
        "\n",
        "4 = needleleaf\n",
        "\n",
        "5 = builtup\n",
        "\n",
        "6 = waterbody"
      ],
      "metadata": {
        "id": "1hvXtuAc7ynx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV with landcover associated with pixel location\n",
        "pix_df = pd.read_csv(os.path.join(data_dir,'_pixel_LC.csv'))"
      ],
      "metadata": {
        "id": "CEd2K0j4VqDO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get 100 random samples from each lc class\n",
        "class1 = pix_df.loc[pix_df['LC'] == 1]\n",
        "lc_df1 = class1.sample(n=100, random_state=10)\n",
        "\n",
        "class2 = pix_df.loc[pix_df['LC'] == 2]\n",
        "lc_df2 = class2.sample(n=100, random_state=10)\n",
        "\n",
        "class3 = pix_df.loc[pix_df['LC'] == 3]\n",
        "lc_df3 = class3.sample(n=100, random_state=10)\n",
        "\n",
        "class4 = pix_df.loc[pix_df['LC'] == 4]\n",
        "lc_df4 = class4.sample(n=100, random_state=10)\n",
        "\n",
        "class5 = pix_df.loc[pix_df['LC'] == 5]\n",
        "lc_df5 = class5.sample(n=100, random_state=10)\n",
        "\n",
        "class6 = pix_df.loc[pix_df['LC'] == 6]\n",
        "lc_df6 = class6.sample(n=100, random_state=10)\n"
      ],
      "metadata": {
        "id": "-un_7Ez7lP_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create table of all 6 classes\n",
        "data = pd.concat([lc_df1,lc_df2,lc_df3,lc_df4,lc_df5,lc_df6], axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "JpvU6iKElyuu",
        "outputId": "8189de98-53d5-40ca-d4c2-5145f5c4d466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            pixel   LC         x          y\n",
              "1661188   4738520  1.0  586595.0  5345255.0\n",
              "7807242  13881631  1.0  596845.0  5323885.0\n",
              "3068976   6811956  1.0  572655.0  5340405.0\n",
              "850259    3561655  1.0  582445.0  5348005.0\n",
              "3792632   7966518  1.0  567675.0  5337705.0\n",
              "...           ...  ...       ...        ...\n",
              "3954712   8207617  6.0  582985.0  5337145.0\n",
              "714189    3306755  6.0  600245.0  5348605.0\n",
              "7111885  12969574  6.0  588415.0  5326015.0\n",
              "3960509   8216196  6.0  583215.0  5337125.0\n",
              "4035162   8327440  6.0  583375.0  5336865.0\n",
              "\n",
              "[600 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dccdd21e-98a4-427a-9b0c-e6cdec2fe1bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel</th>\n",
              "      <th>LC</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1661188</th>\n",
              "      <td>4738520</td>\n",
              "      <td>1.0</td>\n",
              "      <td>586595.0</td>\n",
              "      <td>5345255.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7807242</th>\n",
              "      <td>13881631</td>\n",
              "      <td>1.0</td>\n",
              "      <td>596845.0</td>\n",
              "      <td>5323885.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3068976</th>\n",
              "      <td>6811956</td>\n",
              "      <td>1.0</td>\n",
              "      <td>572655.0</td>\n",
              "      <td>5340405.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>850259</th>\n",
              "      <td>3561655</td>\n",
              "      <td>1.0</td>\n",
              "      <td>582445.0</td>\n",
              "      <td>5348005.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3792632</th>\n",
              "      <td>7966518</td>\n",
              "      <td>1.0</td>\n",
              "      <td>567675.0</td>\n",
              "      <td>5337705.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3954712</th>\n",
              "      <td>8207617</td>\n",
              "      <td>6.0</td>\n",
              "      <td>582985.0</td>\n",
              "      <td>5337145.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714189</th>\n",
              "      <td>3306755</td>\n",
              "      <td>6.0</td>\n",
              "      <td>600245.0</td>\n",
              "      <td>5348605.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7111885</th>\n",
              "      <td>12969574</td>\n",
              "      <td>6.0</td>\n",
              "      <td>588415.0</td>\n",
              "      <td>5326015.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3960509</th>\n",
              "      <td>8216196</td>\n",
              "      <td>6.0</td>\n",
              "      <td>583215.0</td>\n",
              "      <td>5337125.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4035162</th>\n",
              "      <td>8327440</td>\n",
              "      <td>6.0</td>\n",
              "      <td>583375.0</td>\n",
              "      <td>5336865.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>600 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dccdd21e-98a4-427a-9b0c-e6cdec2fe1bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dccdd21e-98a4-427a-9b0c-e6cdec2fe1bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dccdd21e-98a4-427a-9b0c-e6cdec2fe1bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create CSV for each image"
      ],
      "metadata": {
        "id": "OSlo8-jSVprv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_csv(image):\n",
        "  src = rxr.open_rasterio(os.path.join(cf_dir, image))\n",
        "  lister = []\n",
        "  for row in data.iterrows():  # for all pixels in the data dataframe\n",
        "    pix_row = row[1]  # reads the row: pixel, LC, x, y\n",
        "    pix, lc_type, easting, northing = int(pix_row[0]),int(pix_row[1]),pix_row[2],pix_row[3]  #assigns column values to variable\n",
        "    #print(pix,lc_type, 'easting ', easting, 'northing ', northing)  #check for correct variable assignment\n",
        "          \n",
        "    pix_array = src.sel(y=northing, x=easting)\n",
        "    band_data = list(pix_array.values)\n",
        "\n",
        "    # keep bands 2,3,4,5,6,7,8,8A,11,12\n",
        "    columns = ['pixel','lc','2','3','4','5','6','7','8','8a','11','12']\n",
        "    my_vals = band_data[0:8]\n",
        "    my_vals.append(band_data[9])\n",
        "    my_vals.append(band_data[10])\n",
        "    my_vals.insert(0,lc_type)\n",
        "    my_vals.insert(0,pix)\n",
        "    lister.append(my_vals)\n",
        "  image_df = pd.DataFrame(lister, columns=columns)\n",
        "\n",
        "  csv_name = image.replace('.tif', '.csv')\n",
        "  image_df.to_csv(os.path.join(tables_dir, csv_name), index=False)\n",
        "  print(csv_name)"
      ],
      "metadata": {
        "id": "zpT3yCiDuK3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image in os.listdir(cf_dir):\n",
        "  if image.endswith('.tif'):\n",
        "    create_csv(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYFb7WWizbb1",
        "outputId": "b1d8ae57-85d5-422d-89b8-e1db2b180bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33UWP_122_2017-04-01.csv\n",
            "33UWP_122_2017-06-20.csv\n",
            "33UWP_122_2017-08-29.csv\n",
            "33UWP_122_2017-09-08.csv\n",
            "33UWP_122_2018-04-21.csv\n",
            "33UWP_122_2018-05-06.csv\n",
            "33UWP_122_2018-08-09.csv\n",
            "33UWP_122_2018-08-29.csv\n",
            "33UWP_122_2018-09-13.csv\n",
            "33UWP_122_2018-09-18.csv\n",
            "33UWP_122_2018-09-28.csv\n",
            "33UWP_122_2018-10-13.csv\n",
            "33UWP_122_2019-04-01.csv\n",
            "33UWP_122_2019-04-16.csv\n",
            "33UWP_122_2019-04-21.csv\n",
            "33UWP_122_2019-06-30.csv\n",
            "33UWP_122_2019-07-25.csv\n",
            "33UWP_122_2020-04-05.csv\n",
            "33UWP_122_2020-08-08.csv\n",
            "33UWP_122_2020-09-12.csv\n",
            "33UWP_79_2017-05-28.csv\n",
            "33UWP_79_2017-08-01.csv\n",
            "33UWP_79_2017-08-31.csv\n",
            "33UWP_79_2017-09-30.csv\n",
            "33UWP_79_2017-10-15.csv\n",
            "33UWP_79_2018-04-08.csv\n",
            "33UWP_79_2018-07-02.csv\n",
            "33UWP_79_2018-08-21.csv\n",
            "33UWP_79_2018-09-30.csv\n",
            "33UWP_79_2018-10-05.csv\n",
            "33UWP_79_2018-10-10.csv\n",
            "33UWP_79_2018-10-30.csv\n",
            "33UWP_79_2019-08-31.csv\n",
            "33UWP_79_2019-09-15.csv\n",
            "33UWP_79_2020-04-02.csv\n",
            "33UWP_79_2020-04-07.csv\n",
            "33UWP_79_2020-04-12.csv\n",
            "33UWP_79_2020-04-22.csv\n",
            "33UWP_79_2020-07-31.csv\n",
            "33UWP_79_2020-09-09.csv\n",
            "33UWP_79_2020-10-04.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create triplets (train, test)"
      ],
      "metadata": {
        "id": "UQD2WqjLRaBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "# initial list of image doy values (cumulative)\n",
        "doy_list = []\n",
        "doy_image_dict = {}\n",
        "for image in os.listdir(cf_dir):\n",
        "    if image.endswith('.tif'):\n",
        "        doy, year = cumulative_doy(image)\n",
        "        doy_list.append(doy)\n",
        "        doy_image_dict[doy] = image"
      ],
      "metadata": {
        "id": "lr5sQN_mu6MO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "# split into train-test sets\n",
        "test_size = 0.1  # 10% as test\n",
        "random_state = 10  # make sure the same five are in test set every time\n",
        "train, test = train_test_split(doy_list,\n",
        "                               test_size=test_size,\n",
        "                               random_state=random_state)"
      ],
      "metadata": {
        "id": "No5r3qgfRMeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "# check sizes and totals\n",
        "print('train: ', len(train))  #36\n",
        "print('test: ', len(test))  #5\n",
        "print(test) # 648, 821, 988, 241, 148"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfkuQlgQRNVr",
        "outputId": "f8eb9b29-2a18-4b26-91ca-b31a0fc0ffa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train:  36\n",
            "test:  5\n",
            "[648, 821, 988, 241, 148]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "# create a list of random triplets using only training images\n",
        "train_stack = []\n",
        "trial = 0\n",
        "\n",
        "while len(train_stack) < 79:\n",
        "    r1 = random.choice(train)\n",
        "    crit = [x for x in train if (x <= (r1+30)) & (x >= (r1-30)) & (x != r1)]\n",
        "    while len(crit) < 2:\n",
        "        r1 = random.choice(train)\n",
        "        crit = [x for x in train if (x <= (r1+30)) & (x >= (r1-30)) & (x != r1)]\n",
        "    r2 = random.sample(crit, k=2)\n",
        "    triplet = [r1, r2[0],r2[1]]\n",
        "    triplet.sort() # sort in ascending order\n",
        "    triplet = tuple(triplet) # create tuple\n",
        "    while triplet not in train_stack:\n",
        "        train_stack.append(triplet)"
      ],
      "metadata": {
        "id": "rR79wVZTRVIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "# create a list of random triplets using only test images\n",
        "test_stack = []\n",
        "trial = 0\n",
        "\n",
        "while len(test_stack) < 25:\n",
        "    r1 = random.choice(test)\n",
        "    crit = [x for x in doy_list if (x <= (r1+30)) & (x >= (r1-30)) & (x != r1)]\n",
        "    while len(crit) < 2:\n",
        "        r1 = random.choice(test)\n",
        "        crit = [x for x in doy_list if (x <= (r1+30)) & (x >= (r1-30)) & (x != r1)]\n",
        "    r2 = random.sample(crit, k=2)\n",
        "    triplet = [r1, r2[0],r2[1]]\n",
        "    triplet.sort() # sort in ascending order\n",
        "    triplet = tuple(triplet) # create tuple\n",
        "    while triplet not in test_stack:\n",
        "        test_stack.append(triplet)\n",
        "        trial += 1"
      ],
      "metadata": {
        "id": "lbKrt7zaRlwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select triplets for each pixel"
      ],
      "metadata": {
        "id": "QJmKKJu_RwPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dic = {}\n",
        "test_dic = {}\n",
        "for row in data.iterrows(): # for all pixels in the data dataframe\n",
        "  pixel = int(row[1][0])\n",
        "\n",
        "  train_dic[pixel] = random.sample(train_stack, k=10)\n",
        "  test_dic[pixel] = random.sample(test_stack, k=5)"
      ],
      "metadata": {
        "id": "oS8z89luRvKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create training table with variables"
      ],
      "metadata": {
        "id": "eS2mtx62WG6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.io.parsers.readers import read_csv\n",
        "\n",
        "cols = ['pixel','dates','doy_sin','doy_cos','B2_blue','B3_green','B4_red',\n",
        "        'B5_RE1','B6_RE2','B7_RE3','B8_NIR1','B8A_NIR2','B11_SWI1','B12_SWI2',\n",
        "        'doy_sin','doy_cos','B2_blue','B3_green','B4_red','B5_RE1',\n",
        "        'B6_RE2','B7_RE3','B8_NIR1','B8A_NIR2','B11_SWI1','B12_SWI2',\n",
        "        'doy_sin','doy_cos','B2_blue','B3_green','B4_red','B5_RE1',\n",
        "        'B6_RE2','B7_RE3','B8_NIR1','B8A_NIR2','B11_SWI1','B12_SWI2']\n",
        "training_table = pd.DataFrame(columns=cols)\n",
        "\n",
        "\n",
        "for pixel, keys in train_dic.items():  #look at dictionary\n",
        "  for triplet in keys:  # iterate through each triplet in a pixel\n",
        "    lister = []\n",
        "    for date in triplet:\n",
        "      image = doy_image_dict[date]  # get image\n",
        "      doy, year = cumulative_doy(image)\n",
        "      doy_sin, doy_cos = cyclical_doy(doy, year)\n",
        "      \n",
        "      csv_name = image.replace('.tif','.csv')  # get csv name\n",
        "      csv = pd.read_csv(os.path.join(tables_dir,csv_name))  # read csv\n",
        "      csv.set_index('pixel', inplace=True)\n",
        "\n",
        "      my_vals = list(csv.loc[pixel][1:])\n",
        "      my_vals.insert(0, doy_cos)\n",
        "      my_vals.insert(0,doy_sin)\n",
        "      lister.append(my_vals)\n",
        "      my_list = [item for sublist in lister for item in sublist]  # flatten list of doy my_val lists into single list\n",
        "    my_list.insert(0,triplet)\n",
        "    my_list.insert(0,pixel)\n",
        "    training_table.loc[len(training_table)] = my_list"
      ],
      "metadata": {
        "id": "tFQyza1VRrZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'training_table.csv'\n",
        "training_table.to_csv(os.path.join(data_dir,name), index=False)"
      ],
      "metadata": {
        "id": "-VFX07nWWi-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create testing table with variables\n"
      ],
      "metadata": {
        "id": "TUTO6LxEj78d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.io.parsers.readers import read_csv\n",
        "\n",
        "cols = ['pixel','dates','doy_sin','doy_cos','B2_blue','B3_green','B4_red',\n",
        "        'B5_RE1','B6_RE2','B7_RE3','B8_NIR1','B8A_NIR2','B11_SWI1','B12_SWI2',\n",
        "        'doy_sin','doy_cos','B2_blue','B3_green','B4_red','B5_RE1',\n",
        "        'B6_RE2','B7_RE3','B8_NIR1','B8A_NIR2','B11_SWI1','B12_SWI2',\n",
        "        'doy_sin','doy_cos','B2_blue','B3_green','B4_red','B5_RE1',\n",
        "        'B6_RE2','B7_RE3','B8_NIR1','B8A_NIR2','B11_SWI1','B12_SWI2']\n",
        "testing_table = pd.DataFrame(columns=cols)\n",
        "\n",
        "\n",
        "for pixel, keys in test_dic.items():  #look at dictionary\n",
        "  for triplet in keys:  # iterate through each triplet in a pixel\n",
        "    lister = []\n",
        "    for date in triplet:\n",
        "      image = doy_image_dict[date]  # get image\n",
        "      doy, year = cumulative_doy(image)\n",
        "      doy_sin, doy_cos = cyclical_doy(doy, year)\n",
        "      \n",
        "      csv_name = image.replace('.tif','.csv')  # get csv name\n",
        "      csv = pd.read_csv(os.path.join(tables_dir,csv_name))  # read csv\n",
        "      csv.set_index('pixel', inplace=True)\n",
        "\n",
        "      my_vals = list(csv.loc[pixel][1:])\n",
        "      my_vals.insert(0, doy_cos)\n",
        "      my_vals.insert(0,doy_sin)\n",
        "      lister.append(my_vals)\n",
        "      my_list = [item for sublist in lister for item in sublist]  # flatten list of doy my_val lists into single list\n",
        "    my_list.insert(0,triplet)\n",
        "    my_list.insert(0,pixel)\n",
        "    testing_table.loc[len(testing_table)] = my_list"
      ],
      "metadata": {
        "id": "e5JhtevCj--J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'testing_table.csv'\n",
        "testing_table.to_csv(os.path.join(data_dir,name), index=False)"
      ],
      "metadata": {
        "id": "ZTSAiUSAkRtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## end of code"
      ],
      "metadata": {
        "id": "B6TPNLJJFpaG"
      }
    }
  ]
}